{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWABU3ZFNygD8+ydVs9ar4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ansh-Malik1/Conversation-Manager/blob/main/Conversation_Manager.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugd10UvA42BY",
        "outputId": "63faded7-5a5e-4608-8091-4849b380a439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.106.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (4.25.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement groq-openai-client (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for groq-openai-client\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install openai jsonschema requests groq-openai-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR0-T4dR80tI",
        "outputId": "3d36c503-2cd4-4753-9b40-cb764f26aa46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.31.1-py3-none-any.whl (134 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/134.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/134.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.31.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key=userdata.get('GROQ_API_KEY')\n",
        "if api_key:\n",
        "  print(\"API KEY retrieved successfully from secrets\")\n",
        "else:\n",
        "  print(\"Error in retrievin API KEY\")"
      ],
      "metadata": {
        "id": "1DQa7yzWef_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a590c064-e254-4698-d0ce-e521383e8a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API KEY retrieved successfully from secrets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Task 1 :\n",
        "### 1. To maintain a running conversation history with user-assistant chats\n",
        "### 2. To implement summarization history to keep it concise.\n",
        "### 3. To truncate by last n messages/limit by character or word length\n",
        "### 4. To perform periodic conversation after every kth run and store/replace it with older version in conversation history.\n",
        "### 5. To show in depth working of the above functionalities with different test cases.\n"
      ],
      "metadata": {
        "id": "TASrLikvcPF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLMs are stateless which means they do not remember past messages. LLMs generally rely on tokens which are fed to them and these tokens have a limit too. When the limit is reached, the older messages are dropped in order to accomodate the new ones. Therefore we must maintain a list of messages explicitly.\n",
        "\n",
        "Each message has:\n",
        "\n",
        "*   role - \"user\",\"system\",assistant\"\n",
        "*   content - contains the text\n",
        "\n",
        "Approach I have followed to implement this:\n",
        "\n",
        "*   For storing the history, I will be using python dictionaries. These dictonaries will then be chained together using List data structures.\n",
        "*   I will be creating helper function to add messages to 'history'.\n",
        "*   At later stages, this created 'history' can be sent to LLMs.\n",
        "*   This layer will easily seprate conversational memory with the rest of the logic and will be the fundamental step to the whole assignment\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vdHbZdJehbD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict, Optional, Union\n",
        "from copy import deepcopy\n",
        "class ConversationManager:\n",
        "  def __init__(self):\n",
        "    self.history : List[Dict[str,str]]= []\n",
        "    self.run_count=0 # Will be used in later stages to perform summarization after every k-th run\n",
        "\n",
        "  def add_message(self,role:str,content:str):\n",
        "    assert role in (\"user\",\"assistant\",\"system\")\n",
        "    self.history.append({'role':role,'content':content})\n",
        "\n",
        "  def get_history(self)-> List[Dict[str,str]]:\n",
        "    return deepcopy(self.history)\n",
        "\n"
      ],
      "metadata": {
        "id": "90KVOPl4ek_C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing for the above cell :\n",
        "cm = ConversationManager()\n",
        "samples = [\n",
        "    ('user', 'Hi, how are you.'),\n",
        "    ('assistant', 'I am fine. How may I help you'),\n",
        "    ('user', 'I want to understand how LLMs work'),\n",
        "    ('assistant', 'Surely, I can tell you that. Please wait a minute while I gather the information'),\n",
        "]\n",
        "\n",
        "for role, text in samples:\n",
        "    cm.add_message(role, text)\n",
        "\n",
        "print('Full history ({} messages):'.format(len(cm.get_history())))\n",
        "for m in cm.get_history():\n",
        "    print(m['role'], ':', m['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R6TFlhRqcQg",
        "outputId": "d975d0de-83c1-4b38-e74a-88d02d924afe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full history (4 messages):\n",
            "user : Hi, how are you.\n",
            "assistant : I am fine. How may I help you\n",
            "user : I want to understand how LLMs work\n",
            "assistant : Surely, I can tell you that. Please wait a minute while I gather the information\n"
          ]
        }
      ]
    }
  ]
}